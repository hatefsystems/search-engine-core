---
name: "15.4 - Troubleshooting Runbooks & Operational Procedures"
about: Create operational runbooks for common issues, incident response, and system recovery procedures
title: "[M9][documentation] Troubleshooting guide and operational runbooks"
labels: kind/feature, area/documentation, area/devops, priority/P0, status/backlog
assignees: ''
milestone: M9-production
estimated_duration: 4-5 days
dependencies:
  - All production systems deployed (M9)
  - SLOs and monitoring defined (13.1, 13.2)
  - Alert system configured
---

## Summary
Create comprehensive operational runbooks for troubleshooting common issues, responding to incidents, and performing routine maintenance procedures. This includes step-by-step guides for index rebuilds, model rollbacks, cache invalidation, performance degradation, and language-specific issues.

## Context
Operational runbooks are critical for:
- Fast incident response and MTTR reduction
- Consistent troubleshooting procedures
- On-call engineer confidence and effectiveness
- Knowledge preservation (avoid tribal knowledge)
- Training new on-call engineers

## Goals
- **Primary:** Comprehensive runbooks for top 20 operational scenarios
- **Secondary:** Incident response playbooks with escalation paths
- **Stretch:** Automated runbook execution for common tasks

## Tasks

### Core Operational Runbooks

- [ ] **Index Rebuild Procedures**
  ```markdown
  # Runbook: Full Index Rebuild
  
  ## When to Use
  - Index corruption detected
  - Major schema changes
  - Data migration or deduplication
  - Performance degradation (fragmentation)
  
  ## Prerequisites
  - [ ] Backup current index
  - [ ] Schedule maintenance window (2-4 hours)
  - [ ] Notify stakeholders
  - [ ] Verify sufficient disk space (3x index size)
  
  ## Procedure
  
  ### 1. Pre-Rebuild Verification
  ```bash
  # Check current index status
  docker exec mongodb_test mongosh --eval "db.adminCommand({dbStats: 1})"
  
  # Verify backup exists
  ls -lh /backups/mongodb/
  
  # Check disk space
  df -h
  ```
  
  ### 2. Stop Indexing
  ```bash
  # Pause crawler (if running)
  docker exec core /app/crawler --pause
  
  # Stop accepting new documents
  # Set feature flag: INDEXING_ENABLED=false
  ```
  
  ### 3. Backup Current Index
  ```bash
  # MongoDB backup
  docker exec mongodb_test mongosh --eval "
    db.getSiblingDB('search-engine').runCommand({
      createBackup: 1,
      name: 'pre-rebuild-$(date +%Y%m%d-%H%M%S)'
    })
  "
  
  # Redis backup
  docker exec redis redis-cli SAVE
  docker exec redis cp /data/dump.rdb /backups/redis/dump-$(date +%Y%m%d-%H%M%S).rdb
  ```
  
  ### 4. Execute Rebuild
  ```bash
  # Option A: Full reindex from MongoDB
  docker exec core /app/indexer --rebuild --source mongodb --parallel 4
  
  # Option B: Reindex from crawl data
  docker exec core /app/indexer --rebuild --source crawl-archive --parallel 4
  
  # Monitor progress
  watch -n 5 'docker logs core --tail 50 | grep -i "indexed"'
  ```
  
  ### 5. Verification
  ```bash
  # Check document count
  docker exec mongodb_test mongosh --eval "
    db.getSiblingDB('search-engine').pages.countDocuments({})
  "
  
  # Test search functionality
  curl "http://localhost:3000/api/v2/search?q=test&limit=5"
  
  # Verify key queries (smoke test)
  for query in "machine learning" "Ø¢Ù…ÙˆØ²Ø´ Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒÙ†ÙˆÛŒØ³ÛŒ" "æ·±åº¦å­¦ä¹ "; do
    curl "http://localhost:3000/api/v2/search?q=$query" | jq '.results | length'
  done
  ```
  
  ### 6. Resume Operations
  ```bash
  # Re-enable indexing
  # Set feature flag: INDEXING_ENABLED=true
  
  # Resume crawler
  docker exec core /app/crawler --resume
  
  # Monitor for errors
  docker logs core -f
  ```
  
  ## Rollback Procedure
  If rebuild fails or causes issues:
  
  ```bash
  # Stop new indexing
  # Restore from backup (see "Restore from Backup" runbook)
  # Verify restoration
  # Resume operations with old index
  ```
  
  ## Success Criteria
  - [ ] Index document count matches expected (Â±2%)
  - [ ] Key queries return relevant results
  - [ ] Latency within SLOs (P95 < 300ms)
  - [ ] No errors in logs
  - [ ] Stakeholders notified of completion
  
  ## Troubleshooting
  - **Out of disk space:** Delete old backups, increase volume size
  - **Timeout during rebuild:** Reduce parallelism, check DB load
  - **Document count mismatch:** Check for duplicates, verify query filters
  
  ## On-Call Contact
  - Primary: @tech-lead
  - Secondary: @senior-engineer
  - Escalation: @cto
  ```

- [ ] **Model Rollback Procedures**
  ```markdown
  # Runbook: Model Rollback (Embedding/Intent/Spam)
  
  ## When to Use
  - New model causes quality degradation
  - Latency regression after model update
  - Model inference errors or crashes
  - Failed A/B test or interleaving experiment
  
  ## Prerequisites
  - [ ] Identify model version to rollback to
  - [ ] Verify previous model files exist
  - [ ] Check model compatibility with feature store
  
  ## Procedure
  
  ### 1. Identify Issue
  ```bash
  # Check current model version
  docker exec core cat /app/models/version.txt
  
  # Review metrics for anomalies
  # Grafana: Check CTR, latency, error rate dashboards
  
  # Check recent logs for model errors
  docker logs core --since 1h | grep -i "model"
  ```
  
  ### 2. Stop New Model Usage
  ```bash
  # Option A: Feature flag rollback
  # Set MODEL_VERSION=<previous_version> in environment
  
  # Option B: Stop service and swap model files
  docker exec core systemctl stop embedding-service
  ```
  
  ### 3. Restore Previous Model
  ```bash
  # List available model versions
  ls -lh /app/models/embeddings/
  
  # Backup current model (just in case)
  docker exec core mv /app/models/embeddings/current \
                        /app/models/embeddings/backup-$(date +%Y%m%d-%H%M%S)
  
  # Restore previous model
  docker exec core cp /app/models/embeddings/v2.3.0/* \
                        /app/models/embeddings/current/
  
  # Update version file
  echo "v2.3.0" | docker exec -i core tee /app/models/version.txt
  ```
  
  ### 4. Restart Services
  ```bash
  # Restart affected service
  docker exec core systemctl restart embedding-service
  
  # Verify service health
  curl http://localhost:8080/health
  
  # Test model inference
  curl -X POST http://localhost:8080/embed \
       -H "Content-Type: application/json" \
       -d '{"text": "test query"}'
  ```
  
  ### 5. Verification
  ```bash
  # Check model version in use
  curl http://localhost:8080/version
  
  # Run smoke tests
  ./scripts/test-search-quality.sh
  
  # Monitor metrics for 30 minutes
  # - Latency should return to baseline
  # - Error rate should drop to normal
  # - Quality metrics should stabilize
  ```
  
  ## Rollback Decision Matrix
  | Symptom | Severity | Action |
  |---------|----------|--------|
  | Latency +50% | P0 | Immediate rollback |
  | Error rate +10% | P0 | Immediate rollback |
  | CTR -15% | P1 | Investigate, rollback if confirmed |
  | CTR -5% | P2 | Monitor, consider rollback |
  
  ## Success Criteria
  - [ ] Model version confirmed as previous
  - [ ] Metrics return to baseline within 1 hour
  - [ ] No new errors in logs
  - [ ] Team notified of rollback
  
  ## Post-Incident
  - [ ] Root cause analysis (why did new model fail?)
  - [ ] Update model testing procedures
  - [ ] Document lessons learned
  ```

- [ ] **Cache Invalidation & Flush**
  - When to invalidate (data updates, config changes)
  - Redis cache flush (L2 cache)
  - Application-level cache clear (L1 memory)
  - Feature store cache invalidation
  - Selective invalidation (by key pattern)
  - Gradual cache warm-up procedures

- [ ] **Performance Degradation Debugging**
  - Latency spike investigation
  - CPU/memory profiling
  - Database slow query identification
  - Network bottleneck detection
  - Cache hit-rate analysis
  - Concurrency issues (deadlocks, race conditions)

- [ ] **Language-Specific Issues**
  - Query not returning results for specific language
  - Language detection failures
  - Script-specific rendering issues (RTL, CJK)
  - Stopword filtering too aggressive/weak
  - Embedding quality issues for rare languages

### Incident Response Playbooks

- [ ] **Search Results Empty or Poor Quality**
  ```markdown
  # Playbook: No Results or Low-Quality Results
  
  ## Symptoms
  - User reports no results for query
  - Results are irrelevant or low-quality
  - Specific language not working
  
  ## Triage (5 minutes)
  
  ### 1. Reproduce Issue
  ```bash
  # Try exact query user reported
  curl "http://localhost:3000/api/v2/search?q=<user_query>&debug=1"
  
  # Check result count and quality
  ```
  
  ### 2. Check System Health
  ```bash
  # MongoDB connection
  docker exec mongodb_test mongosh --eval "db.adminCommand('ping')"
  
  # Redis connection
  docker exec redis redis-cli PING
  
  # Embedding service
  curl http://localhost:8080/health
  ```
  
  ### 3. Review Debug Output
  ```bash
  # Enable debug mode
  curl "http://localhost:3000/api/v2/search?q=<query>&debug=1" | jq '.debug'
  
  # Check:
  # - Language detection correct?
  # - BM25 scores reasonable?
  # - Stopword filtering appropriate?
  # - Any retrieval errors?
  ```
  
  ## Root Cause Analysis (10-20 minutes)
  
  ### Scenario A: Language Detection Failure
  **Symptoms:** Wrong language detected, script mismatch
  
  **Solution:**
  1. Check language detection confidence: `debug.query_processing.language_confidence`
  2. If low (<0.7), query might be mixed-language
  3. Force correct language: `?q=<query>&lang=en`
  4. If persistent, add query to language detection training set
  
  ### Scenario B: Overly Aggressive Stopword Filtering
  **Symptoms:** Single-word queries return no results, debug shows "all tokens filtered"
  
  **Solution:**
  1. Check stopword filtering decision: `debug.query_processing.stopword_filtering`
  2. Verify context-aware rules applied (single-word queries should NOT be filtered)
  3. If bug detected, file incident report
  4. Workaround: Use exact match mode: `?q="<query>"`
  
  ### Scenario C: Index Coverage Gap
  **Symptoms:** No results for valid topic, especially new/niche content
  
  **Solution:**
  1. Check if documents exist: 
     ```bash
     docker exec mongodb_test mongosh --eval "
       db.getSiblingDB('search-engine').pages.find({
         \$text: {\$search: '<query>'}
       }).count()
     "
     ```
  2. If no documents, trigger crawl for relevant sites
  3. If documents exist but not retrieved, check BM25 scoring
  
  ### Scenario D: Spam Filter False Positive
  **Symptoms:** Legitimate results missing, debug shows high `spamness` score
  
  **Solution:**
  1. Check spamness scores: `debug.results[].features.spamness`
  2. If legitimate site has high spamness (>0.6), add to safe-list
  3. Review spam detection model for false positives
  4. Temporary fix: Lower spam penalty weight
  
  ## Resolution
  - Document root cause
  - Apply fix (code patch, config change, safe-list update)
  - Verify fix with user query
  - Monitor for similar reports
  
  ## Escalation
  - If unresolved in 30 minutes â†’ escalate to @tech-lead
  - If affecting multiple users â†’ P0 incident, page on-call
  ```

- [ ] **High Latency / Timeout Incidents**
  - Latency spike investigation steps
  - Database connection pool saturation
  - Embedding service bottleneck
  - Redis cache overload
  - Network issues
  - Load balancing adjustments

- [ ] **Service Crash / Container Restart Loop**
  - Log analysis for crash causes
  - Memory leak detection
  - Segmentation fault debugging (C++ services)
  - Resource limit adjustments (ulimit, Docker limits)
  - Core dump analysis

- [ ] **Data Corruption / Inconsistency**
  - Detect corruption signs (missing fields, invalid values)
  - Restore from backup procedures
  - Data validation scripts
  - Reprocessing corrupted documents
  - Prevention measures

- [ ] **Alert Fatigue / False Alarms**
  - Review alert thresholds
  - Tune alert sensitivity
  - Aggregate related alerts
  - Create alert suppression rules
  - Alert escalation refinement

### Routine Maintenance Procedures

- [ ] **Daily Health Checks**
  ```bash
  #!/bin/bash
  # daily-health-check.sh
  
  echo "=== Daily Health Check ===="
  echo "Date: $(date)"
  
  # 1. Service Status
  echo "\n--- Service Status ---"
  docker ps | grep -E "core|mongodb|redis|browserless"
  
  # 2. Disk Space
  echo "\n--- Disk Space ---"
  df -h | grep -E "/$|/data"
  
  # 3. Index Size
  echo "\n--- Index Size ---"
  docker exec mongodb_test mongosh --quiet --eval "
    db.getSiblingDB('search-engine').stats()
  " | jq '.dataSize, .storageSize, .indexes'
  
  # 4. Key Metrics (last 24h)
  echo "\n--- Key Metrics ---"
  echo "Total queries: $(docker logs core --since 24h | grep -c 'GET /api/v2/search')"
  echo "Average latency: $(docker logs core --since 24h | grep 'latency_ms' | awk '{sum+=$NF; count++} END {print sum/count}')ms"
  echo "Error rate: $(docker logs core --since 24h | grep -c 'ERROR')"
  
  # 5. Smoke Test
  echo "\n--- Smoke Test ---"
  for query in "test" "Ø¢Ø²Ù…Ø§ÛŒØ´" "æµ‹è¯•"; do
    count=$(curl -s "http://localhost:3000/api/v2/search?q=$query" | jq '.results | length')
    echo "Query '$query': $count results"
  done
  
  echo "\n=== Health Check Complete ==="
  ```

- [ ] **Weekly Index Optimization**
  - Compact indexes (reduce fragmentation)
  - Rebuild statistics
  - Vacuum/clean up deleted documents
  - Update computed fields (HostRank, embeddings)

- [ ] **Monthly Backup Verification**
  - Restore backup to staging environment
  - Verify data integrity
  - Test search functionality on restored data
  - Measure restore time (disaster recovery drill)

- [ ] **Quarterly Security Audit**
  - Review access logs
  - Check for suspicious patterns
  - Update dependencies (security patches)
  - Rotate secrets/credentials
  - Penetration testing

### Monitoring & Alerting Guides

- [ ] **Alert Response Matrix**
  | Alert | Severity | Response Time | Action |
  |-------|----------|---------------|--------|
  | Service Down | P0 | 5 min | Restart service, check logs |
  | Latency >500ms | P1 | 15 min | Check DB load, cache hit-rate |
  | Error Rate >5% | P1 | 15 min | Review logs, rollback if needed |
  | Disk >80% | P2 | 1 hour | Clean up logs, expand volume |
  | Low Cache Hit-Rate | P3 | 1 day | Analyze cache patterns, tune TTL |

- [ ] **Dashboard Guide**
  - Key metrics interpretation
  - Normal ranges and thresholds
  - Anomaly detection patterns
  - Drill-down procedures

- [ ] **Log Analysis Techniques**
  - Useful log queries (grep patterns, JSON parsing)
  - Error classification (transient vs. persistent)
  - Correlation with metrics
  - Log aggregation tools (if available)

## Technical Approach

### Runbook Structure Template
```markdown
# Runbook: <Title>

## Overview
Brief description of the procedure and when to use it.

## Prerequisites
- [ ] Checklist of requirements before starting

## Procedure
### Step 1: <Action>
Detailed instructions with commands.

### Step 2: <Next Action>
Continue with clear steps.

## Verification
How to verify the procedure succeeded.

## Rollback
What to do if the procedure fails.

## Troubleshooting
Common issues and solutions.

## Success Criteria
- [ ] Checklist of completion criteria

## Escalation
Who to contact if help is needed.
```

### Runbook Repository Structure
```
docs/
â”œâ”€â”€ runbooks/
â”‚   â”œâ”€â”€ README.md                       # Runbook index
â”‚   â”œâ”€â”€ operational/
â”‚   â”‚   â”œâ”€â”€ index-rebuild.md
â”‚   â”‚   â”œâ”€â”€ model-rollback.md
â”‚   â”‚   â”œâ”€â”€ cache-invalidation.md
â”‚   â”‚   â””â”€â”€ performance-debugging.md
â”‚   â”œâ”€â”€ incidents/
â”‚   â”‚   â”œâ”€â”€ no-results.md
â”‚   â”‚   â”œâ”€â”€ high-latency.md
â”‚   â”‚   â”œâ”€â”€ service-crash.md
â”‚   â”‚   â””â”€â”€ data-corruption.md
â”‚   â”œâ”€â”€ maintenance/
â”‚   â”‚   â”œâ”€â”€ daily-health-check.sh
â”‚   â”‚   â”œâ”€â”€ weekly-optimization.md
â”‚   â”‚   â””â”€â”€ backup-verification.md
â”‚   â””â”€â”€ monitoring/
â”‚       â”œâ”€â”€ alert-response.md
â”‚       â”œâ”€â”€ dashboard-guide.md
â”‚       â””â”€â”€ log-analysis.md
```

## Acceptance Criteria

### Runbook Coverage
- [ ] Top 10 operational procedures documented (index rebuild, model rollback, etc.)
- [ ] Top 10 incident scenarios covered (no results, high latency, crashes, etc.)
- [ ] Routine maintenance procedures documented (daily, weekly, monthly, quarterly)
- [ ] Alert response matrix created with severity levels and SLAs
- [ ] Escalation paths defined for all scenarios

### Runbook Quality
- [ ] Each runbook has clear step-by-step instructions
- [ ] Commands are copy-pasteable and tested
- [ ] Verification steps included for all procedures
- [ ] Rollback procedures documented where applicable
- [ ] Troubleshooting sections for common issues
- [ ] Realistic time estimates for each procedure

### Usability
- [ ] Runbooks indexed and searchable
- [ ] Runbooks accessible to all on-call engineers
- [ ] Emergency contact information included
- [ ] Runbooks reviewed by on-call team
- [ ] Runbooks tested in staging environment

### Maintenance
- [ ] Runbook update process defined
- [ ] Runbooks versioned in git
- [ ] Review schedule established (quarterly)
- [ ] Feedback mechanism for improvements

## Testing & Validation

### Runbook Testing
- [ ] Execute each runbook in staging environment
- [ ] Verify all commands work as documented
- [ ] Measure actual time vs. estimated time
- [ ] Have new team member follow runbook (usability test)
- [ ] Incorporate feedback and revise

### Disaster Recovery Drill
```yaml
Quarterly Drill:
  1. Simulate production incident (e.g., index corruption)
  2. Follow runbook to resolve
  3. Measure MTTR (Mean Time To Recovery)
  4. Document lessons learned
  5. Update runbooks based on experience
  
Target MTTR:
  - P0 incidents: <30 minutes
  - P1 incidents: <2 hours
  - P2 incidents: <1 day
```

## Documentation

### Runbook Index
Create `docs/runbooks/README.md`:
```markdown
# Operational Runbooks

## Quick Links
- [ðŸš¨ Incident Response](incidents/)
- [ðŸ”§ Operational Procedures](operational/)
- [ðŸ“… Maintenance Schedules](maintenance/)
- [ðŸ“Š Monitoring & Alerts](monitoring/)

## Emergency Contacts
- On-Call Engineer: Pagerduty / Opsgenie
- Tech Lead: @tech-lead (Telegram/Slack)
- Database Admin: @dba (for MongoDB issues)
- Infrastructure: @infra (for Docker/networking)

## Most Used Runbooks
1. [Index Rebuild](operational/index-rebuild.md)
2. [Model Rollback](operational/model-rollback.md)
3. [No Results Debugging](incidents/no-results.md)
4. [High Latency Response](incidents/high-latency.md)
5. [Cache Invalidation](operational/cache-invalidation.md)

## Incident Severity Levels
- **P0:** Service down, data loss, security breach â†’ Page immediately
- **P1:** Major degradation, high latency, errors â†’ Respond within 15 min
- **P2:** Minor issues, low impact â†’ Resolve within business hours
- **P3:** Improvements, optimizations â†’ Scheduled work
```

### On-Call Handbook
Create `docs/runbooks/oncall-handbook.md`:
```markdown
# On-Call Engineer Handbook

## Before Your Shift
- [ ] Test access to all systems (MongoDB, Redis, Docker)
- [ ] Verify alert notifications working
- [ ] Review recent incidents and changes
- [ ] Read updated runbooks

## During Your Shift
- Monitor Grafana dashboards
- Respond to alerts per SLA
- Document all incidents
- Escalate when needed
- Update runbooks if gaps found

## After Your Shift
- [ ] Handoff summary to next on-call
- [ ] File any incident reports
- [ ] Suggest runbook improvements
```

## Notes

### Best Practices
1. **Keep It Simple:** Clear, step-by-step instructions
2. **Test Regularly:** Runbooks must be validated
3. **Update Often:** Incorporate lessons learned
4. **Include Context:** Explain why, not just how
5. **Emergency First:** Prioritize critical scenarios

### Common Pitfalls
- âŒ Runbooks out of date with system changes
- âŒ Commands that don't work (copy-paste errors)
- âŒ Missing verification steps
- âŒ No rollback procedures
- âŒ Overly complex instructions

### Tools & Resources
- [SRE Book - Google](https://sre.google/sre-book/table-of-contents/)
- [Runbook Templates](https://github.com/SkeltonThatcher/run-book-template)
- [PagerDuty Incident Response](https://response.pagerduty.com/)

## Success Metrics
- MTTR reduced by 50% after runbook deployment
- 100% of on-call engineers trained on runbooks
- Zero incidents escalated due to missing runbooks
- Runbooks referenced in 90%+ of incident responses
- Positive feedback from on-call team (NPS >8)

## Related Tasks
- 13.1 - SLI/SLO Definition (defines alert thresholds)
- 13.2 - Health Checks & Metrics (provides monitoring data)
- 13.5 - Runbooks & On-Call (implementation task)
- 15.1 - Architecture Diagrams (visual reference for troubleshooting)

---

**Celebration Criteria:** ðŸŽ‰
- All critical runbooks created and tested
- First disaster recovery drill completed successfully
- MTTR measurably improved
- On-call team confident in runbook coverage

