# ðŸŽ¯ Task 02.1: BM25 Implementation

## ðŸ“… Sprint Info
- **Duration:** 4 days
- **Milestone:** M1 - Core Retrieval
- **Priority:** P0 (Critical Path)
- **Depends On:** Task 01.6 (C++ Integration) âœ…
- **Blocks:** Task 02.3 (Index Builder)
- **Assignee:** TBD

## ðŸŽ¬ What You'll Build
Implement universal BM25 (Best Matching 25) scoring algorithm with field-specific weights. Works for any language automatically.

## ðŸ“‹ Daily Breakdown

### Day 1: BM25 Core Algorithm
- [ ] Implement BM25 scoring formula
- [ ] Add configurable parameters (k1=1.5, b=0.75)
- [ ] Term frequency (TF) calculation
- [ ] Document frequency (DF) calculation
- [ ] Basic unit tests

### Day 2: Field-Specific Weights
- [ ] Implement weighted fields (title:5x, anchors:3x, body:1x)
- [ ] Field-level BM25 scoring
- [ ] Combined score aggregation
- [ ] Test with multi-field documents

### Day 3: Universal Language Support
- [ ] Language-agnostic tokenization integration
- [ ] Unicode-aware term matching
- [ ] Integration with Task 01.6 (TextProcessor)
- [ ] Test with 10+ languages

### Day 4: Optimization & Testing
- [ ] Performance optimization (target: top-200 in <50ms)
- [ ] Memory efficiency improvements
- [ ] Comprehensive test suite
- [ ] Documentation and examples

## âœ… Acceptance Criteria
- [ ] BM25 scores correctly computed per spec
- [ ] Field weights work (title > anchors > body)
- [ ] Works for any language (universal)
- [ ] Performance: Retrieve top-200 in <50ms
- [ ] Unit test coverage â‰¥85%
- [ ] Handles edge cases (empty docs, single term, etc.)

## ðŸŽ‰ Celebration Criteria
âœ… **Demo:** Show BM25 ranking for multi-language queries  
âœ… **Fast:** <50ms for top-200 retrieval  
âœ… **Accurate:** Relevant docs ranked higher  

**ðŸŽŠ Celebration:** Post side-by-side comparison with baseline!

## ðŸ“¦ Deliverables
- `src/search/BM25Scorer.cpp` (300 lines)
- `include/search/BM25Scorer.h` (100 lines)
- `tests/bm25_scorer_test.cpp` (150+ test cases)
- `docs/api/bm25-scoring.md`

## ðŸ’¡ BM25 Formula
```
score(D,Q) = Î£ IDF(qi) Ã— (f(qi,D) Ã— (k1 + 1)) / (f(qi,D) + k1 Ã— (1 - b + b Ã— |D|/avgdl))

Where:
- D = document
- Q = query
- f(qi,D) = term frequency of qi in D
- |D| = length of D in words
- avgdl = average document length
- k1 = term frequency saturation (default: 1.5)
- b = length normalization (default: 0.75)
```

## ðŸš€ Next Steps
âž¡ï¸ **Task 02.2: N-gram Tokenizer** (parallel)  
âž¡ï¸ **Task 02.3: Index Builder** (depends on both)

---

**Build the best ranking algorithm! ðŸ†**

