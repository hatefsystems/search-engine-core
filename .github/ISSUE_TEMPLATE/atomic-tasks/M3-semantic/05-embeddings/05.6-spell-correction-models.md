# ðŸŽ¯ Task 05.6: Spell Correction Models & Vocabulary

## ðŸ“… Sprint Info
- **Duration:** 4 days
- **Milestone:** M3 - Semantic Processing
- **Priority:** P1
- **Depends On:** Task 05.3 (Subword Embeddings) âœ…
- **Blocks:** Task 09.5 (Hybrid Spell Correction Pipeline)
- **Assignee:** TBD

## ðŸŽ¬ What You'll Build
Build comprehensive spell correction infrastructure using three-stage approach: (1) corpus vocabulary with frequencies, (2) character n-gram models for edit distance candidates, (3) embedding-based semantic validation. Works across all languages automatically.

## ðŸ“‹ Daily Breakdown

### Day 1: Corpus Vocabulary & Frequency Analysis
- [ ] Extract vocabulary from indexed documents (100M+ documents)
- [ ] Compute term frequencies and document frequencies
- [ ] Build language-specific frequency dictionaries
- [ ] Implement vocabulary normalization pipeline
- [ ] Store vocabulary in Redis with frequencies
- [ ] Add vocabulary lookup API (<1ms latency)
- [ ] Create vocabulary statistics dashboard

### Day 2: Character N-Gram Models
- [ ] Build character trigram and 4-gram models
- [ ] Implement edit distance computation (Levenshtein)
- [ ] Create candidate generation (edit distance 1-2)
- [ ] Add phonetic similarity (Soundex, Metaphone for supported languages)
- [ ] Optimize for speed: target <1ms for candidate generation
- [ ] Test on multilingual typos
- [ ] Document n-gram statistics per language

### Day 3: Embedding-Based Semantic Validation
- [ ] Implement semantic similarity using subword embeddings
- [ ] Build correction confidence scoring
- [ ] Add context-aware correction (query context)
- [ ] Implement correction ranking (frequency + similarity)
- [ ] Tune confidence thresholds (precision vs recall)
- [ ] Test on real typo datasets
- [ ] Performance optimization: <5ms validation

### Day 4: Integration & Testing
- [ ] Build unified spell correction API
- [ ] Create training data from query logs (optional)
- [ ] Add comprehensive test suite (100+ typo examples)
- [ ] Performance benchmarking across languages
- [ ] Integration with query pipeline
- [ ] Documentation and examples
- [ ] Monitoring and metrics

## âœ… Acceptance Criteria
- [ ] Vocabulary covers â‰¥95% of corpus terms across all languages
- [ ] Character n-gram candidate generation: <1ms
- [ ] Edit distance computation: supports edit distance 1-2
- [ ] Embedding-based validation accuracy: â‰¥90%
- [ ] Overall spell correction precision: â‰¥95%
- [ ] Overall spell correction recall: â‰¥85%
- [ ] Supports 20+ languages automatically
- [ ] False positive rate: <5% on valid words

## ðŸ§ª Testing Checklist
- [ ] Unit tests for vocabulary lookup (20+ test cases)
- [ ] Edit distance computation tests (30+ test cases)
- [ ] Candidate generation tests (40+ test cases)
- [ ] Semantic validation tests (50+ test cases)
- [ ] Multi-language typo tests (10+ languages)
- [ ] Performance benchmarks (latency, throughput)
- [ ] False positive tests (valid words incorrectly flagged)
- [ ] Real query log validation (if available)

## ðŸŽ‰ Celebration Criteria (Definition of Done)
âœ… **Demo Ready:** Correct typos in 5 languages with confidence scores
âœ… **Metric Met:** 95% precision, 85% recall on test dataset
âœ… **Integration:** Successfully integrated into query pipeline
âœ… **Performance:** Three-stage pipeline completes in <10ms total

**ðŸŽŠ Celebration Moment:** Never lose users to typos again!

## ðŸ“¦ Deliverables
- `src/python/spell_correction/vocabulary_builder.py` (250 lines)
- `src/python/spell_correction/ngram_model.py` (200 lines)
- `src/python/spell_correction/edit_distance.py` (150 lines)
- `src/python/spell_correction/semantic_validator.py` (200 lines)
- `src/python/spell_correction/correction_api.py` (150 lines)
- `tests/test_spell_correction.py` (100+ test cases)
- `data/vocabulary/vocab_en.json` (vocabulary files per language)
- `data/ngrams/char_trigrams.json` (n-gram statistics)
- `docs/spell-correction-guide.md`

## ðŸ”— Dependencies & Integration

### Input
```python
# Query with potential typo
{
    "query": "searhc engine",  # Typo: "search"
    "language": "en",
    "context": ["web", "google", "search"]  # Optional query context
}
```

### Output
```python
# Spell correction result
{
    "original": "searhc engine",
    "corrected": "search engine",
    "corrections": [
        {
            "token": "searhc",
            "candidates": [
                {"word": "search", "confidence": 0.95, "edit_distance": 1},
                {"word": "research", "confidence": 0.75, "edit_distance": 2}
            ],
            "selected": "search"
        }
    ],
    "confidence": 0.95,
    "auto_correct": true  # High confidence
}
```

### Three-Stage Pipeline
```python
# Stage 1: Edit Distance Candidate Generation (<1ms)
candidates = generate_edit_distance_candidates(word, max_distance=2)

# Stage 2: Frequency Validation (2-3ms)
valid_candidates = [c for c in candidates if c in vocabulary and freq(c) > threshold]

# Stage 3: Embedding Semantic Validation (5-8ms, only if needed)
ranked_candidates = rank_by_semantic_similarity(query_context, valid_candidates, embeddings)
```

### External Dependencies
- Redis (vocabulary storage)
- NumPy (vector operations)
- Subword embeddings (from Task 05.3)
- Python editdistance or python-Levenshtein
- Optional: pyspellchecker, symspellpy (baselines)

## ðŸš€ Next Steps
âž¡ï¸ **Task 09.5: Hybrid Spell Correction Pipeline** (3 days)
- Integrates spell correction into query processing
- Implements auto-correction and "Did you mean?" suggestions

âž¡ï¸ **Task 05.7: Nightly Lexicon Export** (2 days)
- Automated job to refresh vocabulary and n-grams
- Keeps correction models up-to-date

## ðŸ’¡ Tips & Resources

### Common Pitfalls
- âš ï¸ **Over-correction**: Don't correct valid but rare words (use frequency threshold)
- âš ï¸ **Context ignorance**: Consider query context for ambiguous corrections
- âš ï¸ **Performance**: Stage 3 (embeddings) is expensive, only use when needed
- âš ï¸ **False positives**: Valid names/brands get incorrectly flagged
- âš ï¸ **Language mixing**: Handle code-switching in multilingual queries

### Helpful Resources
- [Peter Norvig: How to Write a Spelling Corrector](https://norvig.com/spell-correct.html)
- [SymSpell: Symmetric Delete Algorithm](https://github.com/wolfgarbe/SymSpell)
- [Levenshtein Distance Algorithm](https://en.wikipedia.org/wiki/Levenshtein_distance)
- [Edit Distance in Python](https://github.com/aflc/editdistance)

### Example Code

#### Vocabulary Builder
```python
import pymongo
import redis
import json
from collections import Counter

class VocabularyBuilder:
    def __init__(self, mongo_uri, redis_url):
        self.mongo_client = pymongo.MongoClient(mongo_uri)
        self.redis_client = redis.Redis.from_url(redis_url)
        self.db = self.mongo_client['search-engine']
        
    def build_vocabulary(self, min_frequency=5):
        """Build vocabulary from corpus"""
        word_counts = Counter()
        doc_counts = Counter()
        
        cursor = self.db.documents.find({}, {"title": 1, "body": 1})
        
        for doc in cursor:
            text = f"{doc.get('title', '')} {doc.get('body', '')}"
            words = self.tokenize(text)
            
            # Update frequencies
            word_counts.update(words)
            doc_counts.update(set(words))
        
        # Filter by frequency
        vocabulary = {
            word: {
                "freq": count,
                "doc_freq": doc_counts[word],
                "idf": math.log(total_docs / doc_counts[word])
            }
            for word, count in word_counts.items()
            if count >= min_frequency
        }
        
        # Store in Redis
        for word, stats in vocabulary.items():
            key = f"vocab:en:{word}"
            self.redis_client.setex(key, 30 * 24 * 3600, json.dumps(stats))
        
        return vocabulary
    
    def tokenize(self, text):
        """Simple tokenization"""
        return text.lower().split()
```

#### Edit Distance Candidate Generator
```python
import editdistance

class CandidateGenerator:
    def __init__(self, vocabulary):
        self.vocabulary = vocabulary
        
    def generate_candidates(self, word, max_distance=2):
        """Generate edit distance candidates"""
        candidates = []
        
        for vocab_word in self.vocabulary:
            distance = editdistance.eval(word, vocab_word)
            if distance <= max_distance:
                candidates.append({
                    "word": vocab_word,
                    "edit_distance": distance,
                    "frequency": self.vocabulary[vocab_word]["freq"]
                })
        
        # Sort by distance, then frequency
        candidates.sort(key=lambda x: (x["edit_distance"], -x["frequency"]))
        
        return candidates[:10]  # Top 10
```

#### Semantic Validator
```python
class SemanticValidator:
    def __init__(self, embedding_service):
        self.embedding_service = embedding_service
        
    def validate_correction(self, original_query, candidates):
        """Rank candidates by semantic similarity"""
        query_embedding = self.embedding_service.get_embedding(original_query)
        
        ranked_candidates = []
        for candidate in candidates:
            candidate_embedding = self.embedding_service.get_embedding(candidate["word"])
            
            # Compute cosine similarity
            similarity = self.cosine_similarity(query_embedding, candidate_embedding)
            
            # Combined score: edit distance + frequency + semantic similarity
            score = (
                0.4 * (1 - candidate["edit_distance"] / 2) +
                0.3 * math.log(candidate["frequency"] + 1) / 10 +
                0.3 * similarity
            )
            
            ranked_candidates.append({
                **candidate,
                "semantic_similarity": similarity,
                "confidence": score
            })
        
        ranked_candidates.sort(key=lambda x: -x["confidence"])
        
        return ranked_candidates
    
    def cosine_similarity(self, a, b):
        """Compute cosine similarity"""
        return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))
```

## ðŸ“Š Success Metrics
- **Precision:** â‰¥95% (correct suggestions / total suggestions)
- **Recall:** â‰¥85% (typos caught / total typos)
- **Latency:** Stage 1: <1ms, Stage 2: 2-3ms, Stage 3: 5-8ms
- **Coverage:** Vocabulary covers â‰¥95% of query terms
- **False Positives:** <5% valid words flagged as typos
- **Multi-language:** Works for 20+ languages

## ðŸŽ“ Learning Outcomes
After completing this task, you will:
- âœ… Build production spell correction systems
- âœ… Implement edit distance algorithms efficiently
- âœ… Combine multiple signals (frequency, semantics, edit distance)
- âœ… Optimize for low-latency NLP pipelines
- âœ… Handle multilingual text correction

---

**Typos don't stand a chance! ðŸŽ¯âœ¨**

