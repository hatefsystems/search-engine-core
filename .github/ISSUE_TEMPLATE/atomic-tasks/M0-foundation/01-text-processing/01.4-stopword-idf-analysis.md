# ðŸŽ¯ Task 01.4: Stopword IDF Analysis

## ðŸ“… Sprint Info
- **Duration:** 5 days
- **Milestone:** M0 - Foundation
- **Priority:** P0 (Critical Path)
- **Depends On:** Task 01.3 (Script Processing) âœ…
- **Blocks:** Task 01.5 (Batch Jobs), Task 09.2 (Stopword Filtering)
- **Assignee:** TBD

## ðŸŽ¬ What You'll Build
Build universal automatic stopword detection using corpus-based IDF (Inverse Document Frequency) analysis. Works for ANY language without manual stopword lists!

## ðŸ“‹ Daily Breakdown

### Day 1: IDF Calculator Setup
- [ ] Design IDF calculation algorithm
- [ ] Build document frequency counter
- [ ] Implement term-document matrix (sparse)
- [ ] Setup Redis for frequency storage
- [ ] Initial tests with small corpus (1K docs)

### Day 2: Corpus Analysis Pipeline
- [ ] Build corpus reader (MongoDB integration)
- [ ] Implement batch processing for large corpus
- [ ] Calculate IDF scores for all terms
- [ ] Identify stopword candidates (IDF < threshold)
- [ ] Test with 100K document corpus

### Day 3: Multi-Language Support
- [ ] Language-specific IDF analysis
- [ ] Cross-language stopword patterns
- [ ] Confidence scoring per stopword
- [ ] Bootstrap with standard lists (fallback)
- [ ] Test across 10+ languages

### Day 4: Redis Export & API
- [ ] Design Redis schema for stopwords
- [ ] Build export pipeline to Redis
- [ ] Create lookup API (<1ms latency)
- [ ] Add confidence score retrieval
- [ ] Performance optimization

### Day 5: Testing & Validation
- [ ] Validate stopword quality (manual spot-check)
- [ ] Performance tests (1M lookups/sec)
- [ ] Integration tests with Tasks 01.1-01.3
- [ ] Documentation and examples
- [ ] Code review

## âœ… Acceptance Criteria
- [ ] IDF-based stopword detection accuracy â‰¥90%
- [ ] Automatically covers 100+ languages
- [ ] Redis lookup latency <1ms
- [ ] Stopword vocabulary covers â‰¥95% of corpus terms
- [ ] Confidence scoring for each stopword
- [ ] Handles languages with no predefined stopword lists
- [ ] Bootstrap fallback for cold-start scenarios

## ðŸ§ª Testing & Validation

### IDF Calculation Test
```python
# High IDF (rare) - NOT stopword
"quantum" â†’ IDF: 8.5 (appears in 0.1% docs)

# Low IDF (common) - IS stopword  
"the" â†’ IDF: 0.8 (appears in 95% docs)
"Ùˆ" (Persian "and") â†’ IDF: 1.2 (appears in 85% docs)
```

### Stopword Detection Threshold
```python
# IDF < 2.0 â†’ Stopword candidate
# Document Frequency > 70% â†’ High confidence stopword
```

### Performance Test
```bash
# Redis lookup speed
python -m pytest tests/test_stopword_lookup.py --benchmark
# Expected: 1M+ lookups/sec, <1ms latency
```

## ðŸŽ‰ Celebration Criteria (Definition of Done)
âœ… **Demo Ready:** Show automatic stopword detection for 5 languages  
âœ… **No Manual Lists:** Works without predefined stopwords  
âœ… **Fast:** <1ms Redis lookup  
âœ… **Accurate:** 90%+ precision on validation set  
âœ… **Universal:** Detects stopwords in any language  

**ðŸŽŠ Celebration Moment:** Demo finding stopwords in a language you don't speak!

## ðŸ“¦ Deliverables
- `src/python/text_processor/idf_analyzer.py` (250-300 lines)
- `src/python/text_processor/stopword_detector.py` (200 lines)
- `src/python/batch/compute_idf.py` (batch processing script)
- `tests/test_idf_analysis.py` (100+ test cases)
- `docs/api/stopword-detection.md`
- `data/stopwords/bootstrap_lists/` (fallback lists)

## ðŸ”— Dependencies & Integration

### Input
```python
# From MongoDB corpus
documents: List[str]  # Processed text from Task 01.3

# From Task 01.2
language_info: LanguageInfo  # For language-specific analysis
```

### Output to Redis
```redis
# Key: "stopword:{lang}:{term}"
# Value: JSON {confidence: float, df: int, idf: float}

HSET stopword:en:the confidence 0.98 df 95000 idf 0.82
HSET stopword:fa:Ùˆ confidence 0.95 df 85000 idf 1.15
```

### API
```python
class StopwordDetector:
    def is_stopword(term: str, language: str, 
                   threshold: float = 0.8) -> bool:
        """Check if term is stopword with confidence threshold"""
        
    def get_stopwords(language: str, 
                     limit: int = 1000) -> List[Tuple[str, float]]:
        """Get top stopwords for language with confidence scores"""
```

## ðŸš€ Next Steps
âž¡ï¸ **Task 01.5: Nightly Batch Jobs** (3 days)  
- Will schedule your IDF refresh nightly
- Keeps stopword lists up-to-date

âž¡ï¸ **Task 09.2: Context-Aware Stopword Filtering** (4 days)  
- Will use your stopword detection for query processing

## ðŸ’¡ Tips & Resources

### Common Pitfalls
- âš ï¸ **Don't use global thresholds:** Language-specific tuning needed
- âš ï¸ **Short documents bias:** Normalize by document length
- âš ï¸ **Domain-specific terms:** "API" might be stopword in tech docs
- âš ï¸ **Cold-start problem:** Bootstrap with standard lists initially

### Helpful Resources
- [TF-IDF Wikipedia](https://en.wikipedia.org/wiki/Tf%E2%80%93idf)
- [sklearn TfidfVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)
- [Redis Data Structures](https://redis.io/docs/manual/data-types/)
- [NLTK Stopwords](https://www.nltk.org/howto/corpus.html#word-lists-and-lexicons) (for bootstrap)

### Example Code
```python
import math
from collections import Counter

def calculate_idf(term: str, corpus: List[str]) -> float:
    """Calculate IDF score for term"""
    N = len(corpus)  # Total documents
    df = sum(1 for doc in corpus if term in doc)  # Document frequency
    
    if df == 0:
        return 0.0
    
    idf = math.log(N / df)
    return idf

def detect_stopwords(corpus: List[str], 
                    idf_threshold: float = 2.0) -> Dict[str, float]:
    """Detect stopwords using IDF analysis"""
    all_terms = Counter()
    for doc in corpus:
        all_terms.update(doc.split())
    
    stopwords = {}
    for term, count in all_terms.items():
        idf = calculate_idf(term, corpus)
        if idf < idf_threshold:
            confidence = 1.0 - (idf / idf_threshold)
            stopwords[term] = confidence
    
    return stopwords
```

## ðŸ“Š Success Metrics
- **Precision:** â‰¥90% of detected stopwords are correct
- **Recall:** â‰¥85% of actual stopwords detected
- **Coverage:** Works for 100+ languages
- **Performance:** <1ms Redis lookup

## ðŸŽ“ Learning Outcomes
After completing this task, you will:
- âœ… Understand IDF and information retrieval basics
- âœ… Build corpus-based linguistic analysis
- âœ… Implement efficient Redis data structures
- âœ… Create language-agnostic NLP systems

## ðŸ“ˆ Corpus Requirements
- **Minimum:** 10K documents per language
- **Recommended:** 100K+ documents
- **Optimal:** 1M+ documents

## ðŸ”¬ Validation Strategy
1. **Automatic:** IDF threshold validation
2. **Manual:** Spot-check top 100 stopwords per language
3. **Comparative:** Compare with NLTK/standard lists (where available)
4. **Query Impact:** Measure search quality improvement

---

**Let's discover stopwords automatically! ðŸ”**

