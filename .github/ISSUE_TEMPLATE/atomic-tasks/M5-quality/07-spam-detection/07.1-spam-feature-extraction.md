# ðŸŽ¯ Task 07.1: Spam Feature Extraction

## ðŸ“… Sprint Info
- **Duration:** 3 days
- **Milestone:** M5 - Quality & Spam Detection
- **Priority:** P1
- **Depends On:** None (can start independently)
- **Blocks:** Task 07.2 (One-Class SVM)
- **Assignee:** TBD

## ðŸŽ¬ What You'll Build
Extract comprehensive spam/quality features from web pages: text/HTML ratio, keyword density, ad density, outlink patterns, content volatility, and boilerplate detection. Works across any language automatically.

## ðŸ“‹ Daily Breakdown

### Day 1: Content Quality Features
- [ ] Implement text/HTML ratio calculator
- [ ] Build keyword density analyzer
- [ ] Add readability scoring (Flesch, etc.)
- [ ] Create content length features
- [ ] Extract title/body quality signals
- [ ] Unit tests (40+ scenarios)

### Day 2: Technical Quality Features
- [ ] Build ad/script density detector
- [ ] Implement outlink pattern analysis
- [ ] Add URL quality scoring
- [ ] Create near-duplicate detection
- [ ] Extract meta tag quality signals
- [ ] Performance optimization

### Day 3: Advanced Features & Validation
- [ ] Implement content volatility tracking
- [ ] Build boilerplate detection
- [ ] Add image/media analysis
- [ ] Create feature normalization
- [ ] Multi-language validation (10+ languages)
- [ ] Documentation

## âœ… Acceptance Criteria
- [ ] 20+ spam features extracted per document
- [ ] Feature extraction <10ms per document
- [ ] Works across 10+ languages automatically
- [ ] Features normalized to [0,1] range
- [ ] Handles missing/malformed content gracefully
- [ ] Feature importance analysis completed

## ðŸ§ª Testing Checklist
- [ ] Unit tests for each feature (50+ cases)
- [ ] Spam vs quality discrimination tests
- [ ] Multi-language feature tests
- [ ] Performance benchmarks (<10ms)
- [ ] Edge case handling (empty pages, broken HTML)

## ðŸŽ‰ Celebration Criteria (Definition of Done)
âœ… **Demo Ready:** Show feature extraction on spam vs quality pages
âœ… **Metric Met:** 20+ features, <10ms extraction time
âœ… **Coverage:** Works for 10+ languages
âœ… **Quality:** Features discriminate spam effectively

**ðŸŽŠ Celebration Moment:** Spam has nowhere to hide!

## ðŸ“¦ Deliverables
- `src/python/quality/feature_extractor.py` (500 lines)
- `src/python/quality/text_analyzer.py` (300 lines)
- `src/python/quality/technical_analyzer.py` (350 lines)
- `tests/test_spam_features.py` (70+ test cases)
- `docs/spam-features-guide.md`

## ðŸ”— Dependencies & Integration

### Input
```python
{
    "doc_id": str,
    "url": str,
    "html": str,
    "title": str,
    "body": str,
    "outlinks": List[str],
    "language": str
}
```

### Output
```python
# Extracted features
{
    "text_html_ratio": float,  # 0.0-1.0
    "keyword_density": float,  # 0.0-1.0
    "ad_density": float,  # 0.0-1.0
    "script_ratio": float,  # 0.0-1.0
    "outlink_count": int,
    "suspicious_outlinks": int,
    "url_depth": int,
    "url_length": int,
    "title_length": int,
    "body_length": int,
    "readability_score": float,
    "boilerplate_ratio": float,
    "near_duplicate_score": float,
    "content_volatility": float,
    "image_text_ratio": float,
    "meta_quality": float,
    "domain_reputation": float,
    # ... 20+ features total
}
```

### Feature Definitions

```python
class SpamFeatureExtractor:
    def extract_features(self, doc: Dict) -> Dict:
        """Extract all spam/quality features"""
        
        features = {}
        
        # Content quality
        features['text_html_ratio'] = self.text_html_ratio(doc['html'], doc['body'])
        features['keyword_density'] = self.keyword_density(doc['body'])
        features['readability_score'] = self.readability(doc['body'], doc['language'])
        
        # Technical quality
        features['ad_density'] = self.ad_density(doc['html'])
        features['script_ratio'] = self.script_ratio(doc['html'])
        features['outlink_count'] = len(doc['outlinks'])
        features['suspicious_outlinks'] = self.count_suspicious_outlinks(doc['outlinks'])
        
        # URL quality
        features['url_depth'] = self.url_depth(doc['url'])
        features['url_length'] = len(doc['url'])
        features['url_quality'] = self.url_quality_score(doc['url'])
        
        # Content structure
        features['title_length'] = len(doc['title'])
        features['body_length'] = len(doc['body'])
        features['boilerplate_ratio'] = self.boilerplate_ratio(doc['html'])
        
        return features
    
    def text_html_ratio(self, html: str, text: str) -> float:
        """Ratio of visible text to HTML (low = spam)"""
        if not html:
            return 0.0
        return min(len(text) / len(html), 1.0)
    
    def keyword_density(self, text: str) -> float:
        """Detect keyword stuffing (high = spam)"""
        if not text:
            return 0.0
        
        words = text.lower().split()
        if len(words) < 10:
            return 0.0
        
        # Find most common word
        from collections import Counter
        most_common = Counter(words).most_common(1)[0]
        density = most_common[1] / len(words)
        
        return density
    
    def ad_density(self, html: str) -> float:
        """Detect advertisement presence (high = spam)"""
        ad_patterns = [
            'google_ad', 'adsense', 'advertisement',
            'ad-banner', 'popup', 'sponsored'
        ]
        
        html_lower = html.lower()
        ad_count = sum(html_lower.count(pattern) for pattern in ad_patterns)
        
        # Normalize by HTML length
        return min(ad_count / 100, 1.0)
    
    def script_ratio(self, html: str) -> float:
        """Ratio of JavaScript to HTML (very high = suspicious)"""
        script_content = self.extract_scripts(html)
        if not html:
            return 0.0
        return min(len(script_content) / len(html), 1.0)
    
    def count_suspicious_outlinks(self, outlinks: List[str]) -> int:
        """Count suspicious outbound links"""
        suspicious = 0
        
        for link in outlinks:
            # Check for known spam patterns
            if any(pattern in link.lower() for pattern in [
                'casino', 'porn', 'viagra', 'pharmacy', 'pills'
            ]):
                suspicious += 1
        
        return suspicious
    
    def url_quality_score(self, url: str) -> float:
        """Score URL quality (clean URLs = higher quality)"""
        score = 1.0
        
        # Penalize for excessive parameters
        if url.count('?') > 0:
            params = url.split('?')[1].count('&')
            score -= min(params * 0.1, 0.5)
        
        # Penalize for suspicious patterns
        suspicious_patterns = ['redirect', 'click', 'track', 'aff']
        for pattern in suspicious_patterns:
            if pattern in url.lower():
                score -= 0.2
        
        return max(score, 0.0)
    
    def boilerplate_ratio(self, html: str) -> float:
        """Detect navigation/footer boilerplate (high = low quality)"""
        # Simplified boilerplate detection
        boilerplate_tags = [
            '<nav', '<footer', '<header', '<aside',
            'menu', 'navigation', 'sidebar'
        ]
        
        html_lower = html.lower()
        boilerplate_count = sum(html_lower.count(tag) for tag in boilerplate_tags)
        
        return min(boilerplate_count / 20, 1.0)
```

## ðŸ’¡ Tips & Resources

### Common Pitfalls
- âš ï¸ **Language bias**: Features must work across languages
- âš ï¸ **False positives**: Legitimate pages can have high ad density
- âš ï¸ **Normalization**: Features need consistent ranges
- âš ï¸ **Performance**: Parsing HTML can be slow, optimize extraction

### Helpful Resources
- [Content Quality Guidelines](https://developers.google.com/search/docs/fundamentals/creating-helpful-content)
- [Spam Detection Techniques](https://en.wikipedia.org/wiki/Email_spam_filtering)
- [Web Spam Detection](https://link.springer.com/article/10.1007/s10791-006-9013-6)

## ðŸ“Š Success Metrics
- **Feature Count:** 20+ features per document
- **Extraction Speed:** <10ms per document
- **Language Coverage:** 10+ languages
- **Discrimination:** Features separate spam/quality effectively
- **Robustness:** Handles malformed content gracefully

## ðŸŽ“ Learning Outcomes
- âœ… Design features for unsupervised learning
- âœ… Extract signals from web content
- âœ… Build language-agnostic feature extractors
- âœ… Handle edge cases in web data
- âœ… Optimize feature extraction for speed

---

**Detecting spam, one feature at a time! ðŸ”ðŸ›¡ï¸**

