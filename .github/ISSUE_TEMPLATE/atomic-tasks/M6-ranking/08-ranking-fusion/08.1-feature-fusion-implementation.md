# üéØ Task 08.1: Feature Fusion Implementation (FinalScore Formula)

## üìÖ Sprint Info
- **Duration:** 4 days
- **Milestone:** M6 - Ranking Fusion
- **Priority:** P0 (Critical Path)
- **Depends On:** Task 09.7 (Feature Gathering) ‚úÖ
- **Blocks:** Task 08.2 (MMR Diversification)
- **Assignee:** TBD

## üé¨ What You'll Build
Implement the FinalScore formula combining multiple ranking signals (BM25, embeddings, authority, quality, freshness, etc.) with configurable weights. Enable multi-signal ranking across all languages.

## üìã Daily Breakdown

### Day 1: Formula Design & Architecture
- [ ] Design FinalScore formula architecture
- [ ] Implement configurable weight system
- [ ] Build feature normalization pipeline
- [ ] Add feature combination logic
- [ ] Create score calculation engine
- [ ] Unit tests (40+ scenarios)

### Day 2: Signal Integration
- [ ] Integrate BM25 scores (weight: 0.55)
- [ ] Add embedding similarity (weight: 0.15)
- [ ] Integrate HostRank authority (weight: 0.10)
- [ ] Add anchor match scoring (weight: 0.06)
- [ ] Integrate structured data boost (weight: 0.05)
- [ ] Add freshness decay (weight: 0.04)
- [ ] Integrate URL quality (weight: 0.03)
- [ ] Add spam penalty (weight: -0.08)
- [ ] Integrate intent alignment (weight: 0.04)

### Day 3: Optimization & Testing
- [ ] Feature normalization optimization
- [ ] Score calculation performance (<2ms per doc)
- [ ] Batch processing support (200 docs)
- [ ] Multi-language validation (10+ languages)
- [ ] Edge case handling (missing features)
- [ ] Comprehensive testing

### Day 4: Integration & Documentation
- [ ] Integrate with re-ranking pipeline
- [ ] Add weight configuration system (JSON/YAML)
- [ ] Build score debugging tools
- [ ] Create monitoring dashboards
- [ ] Documentation and examples

## ‚úÖ Acceptance Criteria
- [ ] FinalScore formula implemented with 9 signals
- [ ] Configurable weights (hot-reload capable)
- [ ] Feature normalization consistent across signals
- [ ] Scoring latency <2ms per document
- [ ] Batch processing: 200 docs in <400ms
- [ ] Works across 10+ languages automatically
- [ ] Missing features handled gracefully (default values)

## üß™ Testing Checklist
- [ ] Unit tests for each signal integration (50+ cases)
- [ ] Weight configuration tests
- [ ] Feature normalization tests
- [ ] Score calculation accuracy tests
- [ ] Performance benchmarks (<2ms)
- [ ] Multi-language tests (10+ languages)
- [ ] Edge cases (missing features, zero scores)

## üéâ Celebration Criteria (Definition of Done)
‚úÖ **Demo Ready:** Show ranking improvement with multi-signal scoring
‚úÖ **Metric Met:** NDCG@10 improvement ‚â•10% vs BM25-only baseline
‚úÖ **Integration:** Successfully integrated into query pipeline
‚úÖ **Performance:** <2ms per document sustained

**üéä Celebration Moment:** Multi-signal ranking is alive!

## üì¶ Deliverables
- `include/ranking/Ranker.h` (C++ header, 150 lines)
- `src/ranking/Ranker.cpp` (C++ impl, 600 lines)
- `src/ranking/FeatureFusion.cpp` (fusion logic, 400 lines)
- `config/ranking_weights.yaml` (weight configuration)
- `tests/test_feature_fusion.cpp` (70+ test cases)
- `docs/ranking/feature-fusion-guide.md`
- `monitoring/ranking_dashboard.json`

## üîó Dependencies & Integration

### FinalScore Formula
```cpp
FinalScore(d|q) =
  0.55 * BM25(d|q)
+ 0.15 * EmbSim(q,d)
+ 0.10 * HostRank(d)
+ 0.06 * AnchorMatch(d|q)
+ 0.05 * StructuredBoost(d,q)
+ 0.04 * FreshnessDecay(d)
+ 0.03 * URLQuality(d)
- 0.08 * Spamness(d)
+ 0.04 * IntentAlign(q,d)
```

### Input Features
```cpp
struct DocumentFeatures {
    std::string doc_id;
    
    // Retrieval signals
    float bm25_score;              // 0-100+ (from BM25)
    float embedding_similarity;    // 0-1 (cosine similarity)
    
    // Authority signals
    float host_rank;              // 0-1 (PageRank)
    int anchor_match_count;       // 0-N (matching anchors)
    
    // Quality signals
    bool has_structured_data;     // Boolean
    float quality_score;          // 0-1 (spam detector)
    float spam_score;             // 0-1 (higher = spammier)
    
    // Freshness & URL
    int64_t publish_timestamp;    // Unix timestamp
    float url_quality;            // 0-1 (URL cleanliness)
    
    // Intent alignment
    std::string detected_intent;  // "info", "trans", "nav"
    std::string query_intent;     // "info", "trans", "nav"
};
```

### Output
```cpp
struct RankedDocument {
    std::string doc_id;
    float final_score;
    
    // Score breakdown for debugging
    struct ScoreBreakdown {
        float bm25_contribution;
        float embedding_contribution;
        float authority_contribution;
        float quality_contribution;
        float freshness_contribution;
        // ... all signal contributions
    } breakdown;
};
```

### Implementation Example

```cpp
#include <vector>
#include <cmath>
#include <algorithm>

class Ranker {
public:
    struct RankingWeights {
        float bm25 = 0.55f;
        float embedding_sim = 0.15f;
        float host_rank = 0.10f;
        float anchor_match = 0.06f;
        float structured_boost = 0.05f;
        float freshness = 0.04f;
        float url_quality = 0.03f;
        float spam_penalty = 0.08f;  // Applied as negative
        float intent_align = 0.04f;
    };
    
    Ranker(const RankingWeights& weights = RankingWeights())
        : weights_(weights) {}
    
    float compute_final_score(const DocumentFeatures& features,
                              const std::string& query_intent) {
        float score = 0.0f;
        
        // BM25 contribution (normalize to 0-1 range)
        score += weights_.bm25 * normalize_bm25(features.bm25_score);
        
        // Embedding similarity (already 0-1)
        score += weights_.embedding_sim * features.embedding_similarity;
        
        // HostRank authority (already 0-1)
        score += weights_.host_rank * features.host_rank;
        
        // Anchor match (normalize by max expected)
        score += weights_.anchor_match * normalize_anchor_match(features.anchor_match_count);
        
        // Structured data boost (binary)
        if (features.has_structured_data) {
            score += weights_.structured_boost;
        }
        
        // Freshness decay
        score += weights_.freshness * compute_freshness_decay(features.publish_timestamp);
        
        // URL quality (already 0-1)
        score += weights_.url_quality * features.url_quality;
        
        // Spam penalty (subtract from score)
        score -= weights_.spam_penalty * features.spam_score;
        
        // Intent alignment
        score += weights_.intent_align * compute_intent_alignment(
            features.detected_intent,
            query_intent
        );
        
        return std::max(0.0f, score);  // Ensure non-negative
    }
    
    std::vector<RankedDocument> rank_documents(
        const std::vector<DocumentFeatures>& candidates,
        const std::string& query_intent) {
        
        std::vector<RankedDocument> ranked;
        
        for (const auto& doc : candidates) {
            RankedDocument ranked_doc;
            ranked_doc.doc_id = doc.doc_id;
            ranked_doc.final_score = compute_final_score(doc, query_intent);
            
            // Compute breakdown for debugging
            ranked_doc.breakdown = compute_score_breakdown(doc, query_intent);
            
            ranked.push_back(ranked_doc);
        }
        
        // Sort by final score descending
        std::sort(ranked.begin(), ranked.end(),
                 [](const auto& a, const auto& b) {
                     return a.final_score > b.final_score;
                 });
        
        return ranked;
    }

private:
    RankingWeights weights_;
    
    float normalize_bm25(float raw_score) {
        // BM25 typically ranges 0-100+, normalize to 0-1
        return std::tanh(raw_score / 50.0f);
    }
    
    float normalize_anchor_match(int count) {
        // Diminishing returns for many anchor matches
        return std::tanh(count / 5.0f);
    }
    
    float compute_freshness_decay(int64_t timestamp) {
        // Exponential decay: newer = higher score
        const int64_t now = std::time(nullptr);
        const int64_t age_days = (now - timestamp) / 86400;
        
        // Decay over 365 days
        return std::exp(-age_days / 365.0f);
    }
    
    float compute_intent_alignment(const std::string& doc_intent,
                                   const std::string& query_intent) {
        // Perfect match = 1.0, mismatch = 0.0
        return (doc_intent == query_intent) ? 1.0f : 0.0f;
    }
    
    ScoreBreakdown compute_score_breakdown(const DocumentFeatures& doc,
                                          const std::string& query_intent) {
        ScoreBreakdown breakdown;
        
        breakdown.bm25_contribution = 
            weights_.bm25 * normalize_bm25(doc.bm25_score);
        breakdown.embedding_contribution = 
            weights_.embedding_sim * doc.embedding_similarity;
        breakdown.authority_contribution = 
            weights_.host_rank * doc.host_rank;
        // ... compute all contributions
        
        return breakdown;
    }
};
```

### Configuration System

```yaml
# config/ranking_weights.yaml
ranking:
  weights:
    bm25: 0.55
    embedding_similarity: 0.15
    host_rank: 0.10
    anchor_match: 0.06
    structured_boost: 0.05
    freshness: 0.04
    url_quality: 0.03
    spam_penalty: 0.08
    intent_align: 0.04
  
  normalization:
    bm25_scale: 50.0
    anchor_match_scale: 5.0
    freshness_decay_days: 365
  
  version: "v1"
```

## üí° Tips & Resources

### Common Pitfalls
- ‚ö†Ô∏è **Scale mismatch**: Different signals have different ranges, normalize carefully
- ‚ö†Ô∏è **Weight explosion**: Ensure weights sum ‚âà1.0 for interpretability
- ‚ö†Ô∏è **Missing features**: Handle gracefully with default values
- ‚ö†Ô∏è **Negative scores**: Clamp final scores to non-negative

### Helpful Resources
- [Learning to Rank Survey](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/MSR-TR-2010-82.pdf)
- [Elasticsearch Function Score](https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-function-score-query.html)
- [Feature Normalization Techniques](https://scikit-learn.org/stable/modules/preprocessing.html)

## üìä Success Metrics
- **Quality:** NDCG@10 improvement ‚â•10% vs BM25-only
- **Latency:** <2ms per document
- **Throughput:** 200 docs in <400ms (batch)
- **Coverage:** All 9 signals integrated
- **Stability:** No crashes on missing features
- **Multi-language:** Works for 10+ languages

## üéì Learning Outcomes
After completing this task, you will:
- ‚úÖ Design multi-signal ranking formulas
- ‚úÖ Implement feature fusion systems
- ‚úÖ Optimize scoring performance
- ‚úÖ Build configurable ranking systems
- ‚úÖ Handle feature normalization properly

---

**Nine signals, one perfect ranking! üéØ‚ú®**

