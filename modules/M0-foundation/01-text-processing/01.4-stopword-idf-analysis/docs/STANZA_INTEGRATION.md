# Stanza Integration Guide - Layer 2 Grammar Verification

## ğŸ¯ Overview

This project uses a **hybrid two-layer architecture** for stopword detection:

- **Layer 1 (Universal)**: IDF-based detection - works for ALL languages (100+)
- **Layer 2 (Enhanced)**: Stanza POS tagging - grammar-aware verification (60+ languages)

The system automatically falls back to Layer 1 if Layer 2 (Stanza) is unavailable.

## ğŸ“Š Architecture Diagram

```
Input Term
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 1: IDF Analysis           â”‚
â”‚  - Calculate IDF score           â”‚
â”‚  - Check against threshold       â”‚
â”‚  - Confidence: 1-(IDF/threshold) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â”‚ Stopword Candidate
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 2: Stanza POS Tagging     â”‚
â”‚  - Check if model available      â”‚
â”‚  - Get POS tag (UPOS)            â”‚
â”‚  - Check if stopword POS         â”‚
â”‚  - Boost/reduce confidence       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â”‚ Hybrid Result
              â–¼
    Final Stopword Decision
    (with grammar metadata)
```

## ğŸš€ Quick Start

### Installation

```bash
# Install dependencies
pip install -r requirements.txt

# Download Stanza models (first time only)
python -c "import stanza; stanza.download('en')"
python -c "import stanza; stanza.download('fa')"
```

### Basic Usage

```python
from text_processing import HybridStopwordDetector

# Initialize detector with Stanza enabled
detector = HybridStopwordDetector(
    redis_url="redis://localhost:6379",
    enable_stanza=True  # Enable Layer 2 (grammar verification)
)

# Check stopword with grammar verification
result = detector.is_stopword("the", "en")

print(f"Term: {result.term}")
print(f"Is stopword: {result.is_stopword}")
print(f"Confidence: {result.confidence}")
print(f"POS tag: {result.pos_tag}")                    # 'DET'
print(f"Grammar verified: {result.grammar_verified}")  # True
print(f"Method: {result.detection_method}")           # 'hybrid'
```

## ğŸŒ Language Support

### Checking Support

```python
# Check if grammar verification available for language
if detector.supports_grammar_verification("fa"):
    print("Persian has Stanza support!")
else:
    print("Persian will use IDF-only mode")
```

### Supported Languages (60+)

| Language | Code | Status | Notes |
|----------|------|--------|-------|
| English | `en` | âœ… | High-quality model |
| Persian (Farsi) | `fa` | âœ… | High-quality model |
| Arabic | `ar` | âœ… | High-quality model |
| German | `de` | âœ… | High-quality model |
| Spanish | `es` | âœ… | High-quality model |
| French | `fr` | âœ… | High-quality model |
| Chinese | `zh` | âœ… | High-quality model |
| Russian | `ru` | âœ… | High-quality model |
| Hindi | `hi` | âœ… | High-quality model |
| Turkish | `tr` | âœ… | High-quality model |
| **+50 more** | ... | âœ… | See [Stanza models](https://stanfordnlp.github.io/stanza/models.html) |

## ğŸ”§ Configuration

### Confidence Adjustment

```python
detector = HybridStopwordDetector(
    enable_stanza=True,
    confidence_boost=1.2,     # 20% boost for grammar-verified stopwords
    confidence_penalty=0.7    # 30% reduction for grammar-rejected terms
)
```

### Model Management

```python
from text_processing import StanzaPOSTagger

tagger = StanzaPOSTagger(
    max_models_in_memory=3,  # Keep only 3 models loaded (LRU eviction)
    model_dir="/path/to/models",  # Custom model directory
    auto_download=True,      # Auto-download on first use
    use_gpu=False           # Use CPU (recommended for production)
)
```

### Environment Variables

```bash
# Set Stanza model directory
export STANZA_RESOURCES_DIR=/app/models/stanza

# Docker volume mounting
docker run -v /host/models:/app/models/stanza my-image
```

## ğŸ“ˆ Examples

### Example 1: True Stopword (Grammar Verified)

```python
result = detector.is_stopword("the", "en")

# Output:
# - IDF: 0.8 (very common)
# - Base confidence: 0.85
# - POS tag: 'DET' (determiner)
# - Grammar verified: True
# - Boosted confidence: 0.98 (0.85 * 1.2)
# - Final decision: STOPWORD âœ…
```

### Example 2: False Positive (Grammar Rejected)

```python
result = detector.is_stopword("API", "en")

# Output:
# - IDF: 1.5 (common in tech docs)
# - Base confidence: 0.85
# - POS tag: 'NOUN' (content word)
# - Grammar verified: True
# - Reduced confidence: 0.60 (0.85 * 0.7)
# - Final decision: NOT A STOPWORD âŒ
```

### Example 3: Persian Stopword

```python
result = detector.is_stopword("Ùˆ", "fa")  # 'and' in Persian

# Output:
# - IDF: 1.2 (very common)
# - Base confidence: 0.90
# - POS tag: 'CCONJ' (coordinating conjunction)
# - Grammar verified: True
# - Boosted confidence: 0.99
# - Final decision: STOPWORD âœ…
```

### Example 4: Unsupported Language (Fallback)

```python
result = detector.is_stopword("test", "tlh")  # Klingon

# Output:
# - IDF: 1.4
# - Base confidence: 0.88
# - POS tag: None (Stanza not available)
# - Grammar verified: False
# - Confidence: 0.88 (no adjustment)
# - Detection method: 'idf'
# - Final decision: STOPWORD (based on IDF only) âœ…
```

## ğŸ¨ POS Tags Reference

### Stopword POS Tags (Function Words)

These POS tags indicate stopwords:

| Tag | Description | Example |
|-----|-------------|---------|
| `ADP` | Adposition (preposition/postposition) | in, on, at, by |
| `AUX` | Auxiliary verb | is, has, will, can |
| `CCONJ` | Coordinating conjunction | and, or, but |
| `DET` | Determiner | the, a, an, this |
| `PART` | Particle | 's, not, to (infinitive) |
| `PRON` | Pronoun | I, you, he, it |
| `SCONJ` | Subordinating conjunction | if, while, because |

### Non-Stopword POS Tags (Content Words)

These POS tags indicate content words (NOT stopwords):

| Tag | Description | Example |
|-----|-------------|---------|
| `NOUN` | Noun | cat, city, quantum |
| `PROPN` | Proper noun | London, Google, API |
| `VERB` | Verb | run, think, build |
| `ADJ` | Adjective | quick, brown, fast |
| `ADV` | Adverb | quickly, very, really |

## ğŸ“Š Performance

### Benchmarks

| Operation | Layer 1 Only | Hybrid (Layer 1 + 2) |
|-----------|--------------|----------------------|
| **Detection accuracy** | ~90% | ~95% |
| **First lookup (cold)** | 0.3ms | 3-5ms (model load) |
| **Cached lookup** | 0.3ms | 0.5ms |
| **False positive rate** | 10-15% | 5-8% |
| **Language coverage** | 100+ | 60+ (enhanced) |

### Optimization Tips

1. **Enable caching**: Use global tagger instance
2. **Batch processing**: Process multiple terms at once
3. **Model preloading**: Download models at build time
4. **Lazy loading**: Only load models when needed
5. **LRU eviction**: Keep only frequently used models in RAM

## ğŸ”¬ Advanced Usage

### Batch Stopword Detection

```python
terms = ["the", "quick", "brown", "fox", "API", "HTTP"]
results = detector.batch_check(terms, "en")

for term, info in results.items():
    print(f"{term}: stopword={info.is_stopword}, POS={info.pos_tag}")
```

### Getting All Stopwords with Grammar Info

```python
# Get top 100 stopwords for English
stopwords = detector.get_stopwords("en", limit=100)

# Filter only grammar-verified stopwords
verified_only = detector.get_stopwords(
    "en",
    limit=100,
    grammar_verified_only=True
)

# Filter by confidence
high_confidence = detector.get_stopwords(
    "en",
    limit=100,
    min_confidence=0.95
)
```

### Exporting to Redis with POS Metadata

```python
# Get stopwords
stopwords = detector.get_stopwords("en", limit=1000)

# Export to Redis with POS tags
count = detector.export_to_redis(stopwords, "en")
print(f"Exported {count} stopwords to Redis")

# Redis structure:
# Key: stopword:en:the
# Fields:
#   - confidence: 0.98
#   - df: 95000
#   - idf: 0.82
#   - pos: "DET"
#   - grammar_verified: "true"
#   - method: "hybrid"
```

### Custom POS Tagger

```python
from text_processing import StanzaPOSTagger

# Create custom tagger
custom_tagger = StanzaPOSTagger(
    max_models_in_memory=5,  # Keep more models in RAM
    auto_download=False,     # Manual model management
    use_gpu=True            # Use GPU if available
)

# Use with detector
detector = HybridStopwordDetector(
    enable_stanza=True,
    stanza_tagger=custom_tagger
)
```

## ğŸ› Troubleshooting

### Issue: Stanza not available

```python
from text_processing import STANZA_AVAILABLE

if not STANZA_AVAILABLE:
    print("Stanza not installed!")
    print("Install with: pip install stanza")
```

### Issue: Model download fails

```bash
# Manual download
python -c "import stanza; stanza.download('en', verbose=True)"

# Or download specific processors only
python -c "import stanza; stanza.download('en', processors='tokenize,pos')"
```

### Issue: Out of memory

```python
# Reduce models in memory
tagger = StanzaPOSTagger(max_models_in_memory=2)

# Or unload all models
tagger.unload_all_models()

# Clear POS tag cache
tagger.clear_cache()
```

### Issue: Slow performance

```python
# Use global singleton (caching)
from text_processing import get_global_tagger
tagger = get_global_tagger()

# Batch processing
results = tagger.batch_tag(["term1", "term2", "term3"], "en")

# Disable Stanza for faster (but less accurate) detection
detector = HybridStopwordDetector(enable_stanza=False)
```

## ğŸ“š References

- [Stanza Official Documentation](https://stanfordnlp.github.io/stanza/)
- [Universal Dependencies POS Tags](https://universaldependencies.org/u/pos/)
- [Stanford NLP Group](https://nlp.stanford.edu/)

## ğŸ“ Best Practices

1. **Use hybrid mode for production** - Best accuracy
2. **Fallback to IDF-only for speed** - When latency critical
3. **Download models at build time** - Avoid runtime delays
4. **Use global tagger for caching** - Better performance
5. **Monitor model memory usage** - Set appropriate limits
6. **Test with your corpus** - Validate accuracy for your domain
7. **Use grammar_verified flag** - Debug confidence adjustments

## ğŸ“Š Statistics API

```python
# Get statistics for language
stats = detector.get_statistics("en")

print(stats)
# {
#     'language': 'en',
#     'stanza_available': True,
#     'grammar_support': True,
#     'detection_method': 'hybrid',
#     'stanza_languages_supported': 60,
#     'stanza_models_loaded': 2
# }
```

## ğŸš€ Next Steps

- See [QUICK_START.md](QUICK_START.md) for basic usage
- See [ALGORITHMS.md](ALGORITHMS.md) for technical details
- See [README.md](README.md) for full project overview

